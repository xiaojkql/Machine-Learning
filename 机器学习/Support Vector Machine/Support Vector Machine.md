### 第二章 模型评估和选择

#### 2.1经验误差和过拟合

概念：

错误率

精度

误差、训练误差(training error)或者经验误差(empirical error)

泛化误差(generalization error)

最小化经验误差成为目标

过拟合：将训练样本自身具有的特点当成整个样本具有的普遍特点。机器学习面临的关键障碍，所以各个算法都有针对此的措施。

欠拟合：没有学习到整个样本所具有的一些一般特征规律

学习能力

模型选择：多种学习算法，多种参数配置。

那么如何进行模型评估和选择呢？

#### 2.2 评估方法

总体：模型泛化误差最小。

测试集(testing set)，测试误差(testing error)，与训练集互斥

从数据集中同时产生训练集和测试集

##### 2.2.1 留出法(hold out)

数据集D = 训练集S U 测试集T

数据分布的一致性，避免额外的偏差

采样(sampling)，分层采样(stratified sampling)

训练集与测试集的划分应该多次进行随机分配

##### 2.2.2 交叉验证法(cross validation)

k折交叉验证(k fold cross validation)

随机多次k折交叉验证

留一法(leave one out LOO)，不受样本随机划分的影响(只有唯一的划分方式)，留一法中实际评估的模型与期望评估的用D训练出的模型很相似，留一法被认为很准确。缺陷：计算量大，且未必准确。

##### 2.2.3 自助法

前述的方法存在因样本不同而导致存在一定程度的偏差

会改变数据集的分布方式，从而引入模型偏差

##### 2.2.4 调参和最终模型

模型选择确定以后，还需要对模型中的参数进行设定(调节参数)

工作量很大，而往往参数对模型影响很大

两种参数：

算法的参数，亦称超参数(hyperparameter)，数目一般很少(10以内)，往往人工设定，然后通过评估进行选择。

模型的参数，需要进行学习进行选择。

最终在训练集上学习的模型才提交给用户

验证集(validation set)，用验证集来进行模型选择和调参，用测试集来评估模型学习算法的泛化能力。

#### 2.3 性能度量

评估泛化能力，需要有效可行的实验估计方法，还需衡量模型泛化能力的评价标准，即性能度量(performance measure)，性能度量反应了任务需求。

预测任务中，评估学习器f的性能，就需要把学习器预测的结果与真实标记进行比较。

---回归任务中常用均方误差

分类任务：

##### 2.3.1 错误率与精度

最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务。

##### 2.3.2 查准率和查全率及F1

查准率(precision)、查全率(recall)，两者是相互矛盾的。

真正类(true positive)、假正例(false positive)，真反例(true negative)，假反例(false negative)：TP、FP、TN、FN。

混淆矩阵(confusion matrix)

平衡点(Break-Even Point BEP)，过于简化

F1度量基于调和平均而定义的

$F_{\beta}$是基于加权调和平均而定义的，能表达出对查准率和查全率的不同偏好

当有多个混淆矩阵时：

宏查准率(macro-P)、宏查全率(macro-R)、宏F1(macro-F1)

微查准率(micro-P)、微查全率(micro-R)、微F1(micro-F1)

##### 2.3.3 ROC与AUC

背景：学习器给测试样本产生一个实值或概率预测，然后与一个分类阀值进行比较。

##### 2.3.4 代价敏感错误率与代价曲线

权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价”

代价矩阵(cost matrix)

代价敏感(cost sensitive)

#### 2.4 比较检验

实验评估方法+性能度量可以对学习器进行评估比较。

北京在测试集上评估模型的泛化能力是不准确的

统计假设检验(hypothesis test)

学习器A的泛化能力比学习器B好，那么是否在统计意义上有A优于B呢？

##### 2.4.1 假设检验

假设：对学习器泛化错误率分布的某种判断和猜想，可根据测试错误率推出泛化错误率的分布

在m个样本测试集上，泛化错误率测得是p_f的概率。

单个学习器的检验：二项检验(一次样本分布的检验)  t检验(取平均的检验)

##### 2.4.2 交叉验证t检验

##### 2.4.3 McNemar 检验

##### 2.4.4 Friedman检验与Nemenyi后续检验

#### 2.5 偏差和方差

通过实验估计学习器的泛化能力，为什么具有这样的性能，即偏差-方差分解(bias-variance decomposition) 



